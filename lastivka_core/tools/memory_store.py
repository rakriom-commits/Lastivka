# -*- coding: utf-8 -*-
# lastivka_core/tools/memory_store.py
from pathlib import Path
from datetime import datetime, timedelta
import json
import logging
from tools.emotion_engine import EmotionEngine

logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(message)s",
    handlers=[
        logging.FileHandler("C:/Lastivka/lastivka_core/logs/memory_store.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)

# === Fallback-Ñ„Ð°Ð¹Ð» Ð´Ð»Ñ Ð›ÐžÐ“Ð†Ð’ (legacy) ===
LEGACY_MEMORY_FILE = Path(__file__).resolve().parents[1] / "logs" / "memory_store.json"
LEGACY_MEMORY_FILE.parent.mkdir(parents=True, exist_ok=True)

# ÐšÐ¾Ð¼Ð°Ð½Ð´Ð¸ Ð¿Ð°Ð¼'ÑÑ‚Ñ–, ÑÐºÑ– ÐÐ• Ð¼Ð°ÑŽÑ‚ÑŒ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð¿Ð»ÑŽÐ²Ð°Ñ‚Ð¸ÑÑŒ Ñ‚Ñ€Ð¸Ð³ÐµÑ€Ð°Ð¼Ð¸
MEMORY_COMMAND_MARKERS = (
    "Ð·Ð°Ð¿Ð°Ð¼â€™ÑÑ‚Ð°Ð¹:", "Ð·Ð°Ð¿Ð°Ð¼'ÑÑ‚Ð°Ð¹:", "Ð·Ð°Ð¿Ð°Ð¼ÑÑ‚Ð°Ð¹:",
    "Ñ‰Ð¾ Ñ‚Ð¸ Ð¿Ð°Ð¼â€™ÑÑ‚Ð°Ñ”Ñˆ Ð¿Ñ€Ð¾", "Ñ‰Ð¾ Ñ‚Ð¸ Ð¿Ð°Ð¼'ÑÑ‚Ð°Ñ”Ñˆ Ð¿Ñ€Ð¾",
    "Ð´ÑƒÐ¼ÐºÐ¸", "Ð¿Ð°Ð¼â€™ÑÑ‚ÑŒ", "Ð¿Ð°Ð¼'ÑÑ‚ÑŒ", "ÑÐ¿Ð¾Ð³Ð°Ð´Ð¸",
)

# === Ð“Ð½ÑƒÑ‡ÐºÐµ Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ Ð´Ð¾ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð³Ð¾ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€Ð° Ð¿Ð°Ð¼Ê¼ÑÑ‚Ñ– ===
try:
    from main.memory_manager import memory as _MEM
except ImportError:
    try:
        from memory_manager import memory as _MEM
    except ImportError:
        _MEM = None

# Ð†Ð½Ñ–Ñ†Ñ–Ð°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ EmotionEngine
emotion_engine = EmotionEngine()

def _ensure_legacy_file():
    if not LEGACY_MEMORY_FILE.exists():
        default_memory = {"thoughts": [], "triggers": {}}
        LEGACY_MEMORY_FILE.write_text(json.dumps(default_memory, ensure_ascii=False, indent=2), encoding="utf-8")

def load_memory():
    """Legacy: Ñ‡Ð¸Ñ‚Ð°Ñ” /logs/memory_store.json."""
    _ensure_legacy_file()
    try:
        data = json.loads(LEGACY_MEMORY_FILE.read_text(encoding="utf-8") or "{}")
        if not isinstance(data, dict):
            raise json.JSONDecodeError("ÐÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ JSON", doc=str(data), pos=0)
        data.setdefault("thoughts", [])
        data.setdefault("triggers", {})
        return data
    except json.JSONDecodeError as e:
        raise e

def save_memory(memory):
    """Legacy: Ð¿Ð¸ÑˆÐµ Ñƒ /logs/memory_store.json."""
    LEGACY_MEMORY_FILE.write_text(json.dumps(memory, ensure_ascii=False, indent=2), encoding="utf-8")

def log_thought(thought):
    """Legacy: Ð´ÑƒÐ±Ð»ÑŽÑ” Â«ÑˆÐ²Ð¸Ð´ÐºÑ– Ð´ÑƒÐ¼ÐºÐ¸Â» Ñƒ /logs."""
    memory = load_memory()
    record = {"ts": datetime.now().isoformat(), "text": thought}
    memory.setdefault("thoughts", []).append(record)
    save_memory(memory)

def recall_memory():
    memory = load_memory()
    thoughts = memory.get("thoughts", [])
    if thoughts:
        return thoughts[-1].get("text", "")
    return None

def search_memories(text):
    memory = load_memory()
    text = (text or "").lower()
    results = []
    for section, entries in memory.items():
        entries = [entries] if isinstance(entries, dict) else (entries or [])
        for entry in entries:
            if isinstance(entry, dict):
                value = str(entry.get("text") or entry.get("value") or "")
                if text and text in value.lower():
                    results.append(f"[{section}] {value}")
    return "\n".join(results) if results else "[â›”ï¸] ÐÑ–Ñ‡Ð¾Ð³Ð¾ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾."

def summarize_memories():
    memory = load_memory()
    summary = {}
    for key, val in memory.items():
        summary[key] = (len(val) if isinstance(val, list) else 1)
    lines = [f"{section.capitalize()}: {count}" for section, count in summary.items()]
    return "ðŸ§¾ Ð—Ð²ÐµÐ´ÐµÐ½Ð½Ñ Ð¿Ð°Ð¼Ê¼ÑÑ‚Ñ–:\n" + "\n".join(lines) if lines else "[â›”ï¸] ÐŸÐ°Ð¼Ê¼ÑÑ‚ÑŒ Ð¿Ð¾Ñ€Ð¾Ð¶Ð½Ñ."

def recall_from_question(question):
    def normalize(word):
        word = (word or "").lower()
        for ending in ["Ð¸", "Ñ–", "Ñ", "ÑŽ", "Ñ”", "Ð¾", "Ñƒ", "Ðµ"]:
            if word.endswith(ending):
                return word[:-1]
        return word
    q = normalize(question)
    memory = load_memory()
    found = []
    for section, entries in memory.items():
        entries = [entries] if isinstance(entries, dict) else (entries or [])
        for entry in entries:
            if isinstance(entry, dict):
                value = str(entry.get("text") or entry.get("value") or "")
                if q and q in normalize(value):
                    found.append(f"[{section}] {value}")
    return "\n".join(found) if found else "ðŸ™ˆ ÐÑ–Ñ‡Ð¾Ð³Ð¾ Ð¿Ð¾Ð´Ñ–Ð±Ð½Ð¾Ð³Ð¾ Ð½Ðµ Ð·Ð³Ð°Ð´ÑƒÑ”Ñ‚ÑŒÑÑ..."

def purge_old_thoughts(days=30):
    memory = load_memory()
    thoughts = memory.get("thoughts", []) or []
    threshold = datetime.now() - timedelta(days=days)
    filtered = []
    for entry in thoughts:
        try:
            ts = datetime.fromisoformat(entry.get("ts", ""))
            if ts >= threshold:
                filtered.append(entry)
        except Exception:
            continue
    if len(filtered) != len(thoughts):
        memory["thoughts"] = filtered
        save_memory(memory)
        return f"ðŸ§¹ ÐžÑ‡Ð¸Ñ‰ÐµÐ½Ð¾ {len(thoughts) - len(filtered)} Ð·Ð°ÑÑ‚Ð°Ñ€Ñ–Ð»Ð¸Ñ… Ð·Ð°Ð¿Ð¸ÑÑ–Ð² Ð´ÑƒÐ¼Ð¾Ðº."
    return "âœ… ÐžÑ‡Ð¸Ñ‰ÐµÐ½Ð½Ñ Ð½Ðµ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±ÑƒÐ²Ð°Ð»Ð¾ÑÑ."

def _normalize_trigger_response(response):
    """Ð£Ð½Ñ–Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ñ‚Ñ€Ð¸Ð³ÐµÑ€Ð° Ð´Ð¾ ÑÐ»Ð¾Ð²Ð½Ð¸ÐºÐ°."""
    if isinstance(response, dict) and "text_to_say" in response:
        resp = dict(response)
        resp.setdefault("log_text", f"ðŸ“Š Ñ‚Ñ€Ð¸Ð³ÐµÑ€: {resp['text_to_say']}")
        resp.setdefault("tone", "Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð¸Ð¹")
        resp.setdefault("speed", 180)
        resp.setdefault("intensity", 0.3)
        return resp
    if isinstance(response, tuple):
        text = str(response[0]) if response else ""
    else:
        text = str(response)
    text_clean = text.strip().lstrip("ðŸ“Š").strip()
    return {
        "text_to_say": text_clean,
        "log_text": f"ðŸ“Š Ñ‚Ñ€Ð¸Ð³ÐµÑ€: {text_clean}",
        "tone": "Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð¸Ð¹",
        "speed": 180,
        "intensity": 0.3,
    }

def check_triggers(input_text):
    """ÐŸÐ¾Ð²ÐµÑ€Ñ‚Ð°Ñ” ÑÐ»Ð¾Ð²Ð½Ð¸Ðº: {text_to_say, log_text, tone, speed, intensity} Ð°Ð±Ð¾ None."""
    txt = (input_text or "").strip().lower()
    # Ð†Ð³Ð½Ð¾Ñ€ÑƒÑ”Ð¼Ð¾ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸ Ð¿Ð°Ð¼'ÑÑ‚Ñ–
    if any(marker in txt for marker in MEMORY_COMMAND_MARKERS):
        return None
    # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° ÐµÐ¼Ð¾Ñ†Ñ–Ð¹Ð½Ð¸Ñ… Ñ‚Ñ€Ð¸Ð³ÐµÑ€Ñ–Ð² Ñ‡ÐµÑ€ÐµÐ· EmotionEngine
    detected = emotion_engine.detect_emotion(txt)
    if detected["emotion"]:
        return _normalize_trigger_response({
            "text_to_say": detected["reaction"],
            "log_text": f"ðŸ“Š ÐµÐ¼Ð¾Ñ†Ñ–Ñ: {detected['emotion']}",
            "tone": detected["tone"],
            "speed": detected["speed"],
            "intensity": detected["intensity"]
        })
    # Fallback: Ñ‚Ñ€Ð¸Ð³ÐµÑ€Ð¸ Ð· memory_manager Ð°Ð±Ð¾ legacy
    try:
        if _MEM is not None:
            triggers = _MEM.get_triggers()
        else:
            legacy = load_memory()
            triggers = legacy.get("triggers", {}) or {}
        logger.debug(f"[DEBUG]: Triggers checked: {triggers}")
        for key, response in triggers.items():
            key_l = (key or "").lower()
            if key_l and key_l in txt:
                logger.debug(f"[DEBUG]: Trigger matched: {key} -> {response}")
                return _normalize_trigger_response(response)
    except Exception as e:
        logger.error(f"[ERROR] ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ¸ Ñ‚Ñ€Ð¸Ð³ÐµÑ€Ñ–Ð²: {e}")
    return None